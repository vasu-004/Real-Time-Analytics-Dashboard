# ğŸ—ï¸ Architecture Documentation

## System Architecture

### High-Level Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Data Sources                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚   VM Metrics     â”‚           â”‚  Web Application â”‚           â”‚
â”‚  â”‚                  â”‚           â”‚     Metrics      â”‚           â”‚
â”‚  â”‚  â€¢ CPU Usage     â”‚           â”‚  â€¢ Active Users  â”‚           â”‚
â”‚  â”‚  â€¢ Memory Usage  â”‚           â”‚  â€¢ Request Rate  â”‚           â”‚
â”‚  â”‚  â€¢ Disk I/O      â”‚           â”‚  â€¢ Response Time â”‚           â”‚
â”‚  â”‚  â€¢ Network       â”‚           â”‚  â€¢ Error Rate    â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚                    â”‚
                      â–¼                    â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚      Data Collectors (Python)           â”‚
         â”‚  â€¢ vm-metrics-collector.py              â”‚
         â”‚  â€¢ webapp-metrics-collector.py          â”‚
         â”‚  â€¢ Sends data every 10 seconds          â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚      AWS Kinesis Data Stream            â”‚
         â”‚  â€¢ Stream: real-time-analytics-stream   â”‚
         â”‚  â€¢ 1 MB/sec write capacity per shard    â”‚
         â”‚  â€¢ 24-hour data retention               â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚      AWS Lambda Function                â”‚
         â”‚  â€¢ Function: kinesis-analytics-processorâ”‚
         â”‚  â€¢ Runtime: Node.js 14.x                â”‚
         â”‚  â€¢ Triggered by Kinesis events          â”‚
         â”‚  â€¢ Processes & enriches data            â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚      AWS DynamoDB Table                 â”‚
         â”‚  â€¢ Table: analytics-data                â”‚
         â”‚  â€¢ On-demand billing mode               â”‚
         â”‚  â€¢ Partition Key: id                    â”‚
         â”‚  â€¢ Sort Key: timestamp                  â”‚
         â”‚  â€¢ Point-in-Time Recovery enabled       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚      Web Dashboard (Browser)            â”‚
         â”‚  â€¢ Real-time data visualization         â”‚
         â”‚  â€¢ Chart.js for charts                  â”‚
         â”‚  â€¢ AWS SDK for data fetching            â”‚
         â”‚  â€¢ Auto-refresh every 5 seconds         â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Component Details

### 1. Data Collectors

**Purpose:** Collect metrics from VM and web application

**Technology:** Python 3.8+

**Libraries:**
- `boto3` - AWS SDK for Python
- `psutil` - System monitoring
- `requests` - HTTP client

**Metrics Collected:**

**VM Metrics:**
- CPU: Usage %, per-core usage, frequency
- Memory: Total, used, available, swap
- Disk: Usage, read/write bytes, I/O counts
- Network: Bytes sent/received, packets, errors
- System: Hostname, platform, uptime

**Web App Metrics:**
- Active users count
- Requests per second
- Response time (ms)
- Error rate (%)
- Traffic sources (direct, organic, referral, social)

### 2. AWS Kinesis Stream

**Purpose:** Ingest real-time streaming data

**Configuration:**
- **Name:** `real-time-analytics-stream`
- **Shards:** 1 (scalable to N)
- **Retention:** 24 hours
- **Encryption:** Optional (KMS)

**Capacity per Shard:**
- **Write:** 1 MB/sec or 1,000 records/sec
- **Read:** 2 MB/sec or 5 transactions/sec

**Cost:** ~$0.015/hour per shard = ~$11/month

### 3. AWS Lambda Function

**Purpose:** Process Kinesis records and store in DynamoDB

**Configuration:**
- **Name:** `kinesis-analytics-processor`
- **Runtime:** Node.js 14.x
- **Memory:** 256 MB
- **Timeout:** 30 seconds
- **Concurrency:** Default (1000)

**IAM Permissions:**
- Read from Kinesis Stream
- Write to DynamoDB Table
- Write to CloudWatch Logs

**Processing Logic:**
1. Receive batch of records from Kinesis
2. Decode base64-encoded data
3. Parse JSON payload
4. Enrich with metadata
5. Write to DynamoDB
6. Return processing results

### 4. AWS DynamoDB

**Purpose:** Store processed analytics data

**Configuration:**
- **Name:** `analytics-data`
- **Billing:** On-demand (pay per request)
- **Partition Key:** `id` (String)
- **Sort Key:** `timestamp` (Number)

**Features Enabled:**
- DynamoDB Streams (for change capture)
- Point-in-Time Recovery (automated backups)
- Encryption at rest (AWS managed)

**Data Model:**
```json
{
  "id": "uuid-string",
  "timestamp": 1234567890123,
  "type": "vm-metrics | webapp-metrics",
  "source": "hostname or URL",
  "cpu": { ... },
  "memory": { ... },
  "usage": { ... },
  "performance": { ... }
}
```

### 5. Web Dashboard

**Purpose:** Visualize real-time analytics data

**Technology:**
- HTML5
- CSS3 (Glassmorphism design)
- Vanilla JavaScript
- Chart.js (charts)
- AWS SDK for JavaScript

**Features:**
- ğŸ“Š Real-time metric cards
- ğŸ“ˆ Live updating charts
- ğŸ¨ Modern glassmorphic design
- ğŸŒ™ Dark mode
- âœ¨ Smooth animations
- ğŸ“± Responsive layout

**Update Frequency:** 5 seconds (configurable)

## Data Flow

### Write Path (Data Ingestion)

```
1. Data Collector runs every 10 seconds
   â†“
2. Collects system/app metrics
   â†“
3. Formats data as JSON
   â†“
4. Sends to Kinesis via boto3
   â†“
5. Kinesis stores in shard buffer
   â†“
6. Lambda polls for new records
   â†“
7. Lambda processes batch (up to 100 records)
   â†“
8. Lambda writes to DynamoDB
   â†“
9. DynamoDB confirms write
   â†“
10. Data available for queries
```

**Latency:** ~1-3 seconds end-to-end

### Read Path (Dashboard Query)

```
1. Dashboard polls every 5 seconds
   â†“
2. Queries DynamoDB via AWS SDK
   â†“
3. DynamoDB returns latest records
   â†“
4. Dashboard processes data
   â†“
5. Updates metric cards
   â†“
6. Updates charts
   â†“
7. User sees real-time updates
```

**Latency:** < 1 second

## Scalability

### Horizontal Scaling

**Kinesis:**
- Add shards for higher throughput
- Each shard: +1 MB/sec write, +2 MB/sec read
- Auto-scaling available

**Lambda:**
- Auto-scales to 1000 concurrent executions (default)
- Can request higher limits
- Provisioned concurrency for consistent performance

**DynamoDB:**
- On-demand mode auto-scales
- Or use provisioned mode with auto-scaling
- Global Tables for multi-region deployment

### Vertical Scaling

**Lambda:**
- Increase memory (128 MB - 10 GB)
- CPU scales with memory

**DynamoDB:**
- Increase provisioned capacity
- Use DAX for caching (microsecond latency)

## High Availability

### Built-in HA Features

âœ… **Kinesis:** Multi-AZ replication  
âœ… **Lambda:** Multi-AZ execution  
âœ… **DynamoDB:** Multi-AZ replication  
âœ… **S3 (for Lambda code):** 99.999999999% durability  

### Disaster Recovery

**RTO (Recovery Time Objective):** < 1 hour  
**RPO (Recovery Point Objective):** < 5 minutes

**Backup Strategy:**
- DynamoDB Point-in-Time Recovery (35 days)
- Lambda code in S3 (version control)
- Infrastructure as Code (recreate easily)

## Security

### Authentication & Authorization

**Data Collectors:**
- Use IAM user/role credentials
- Least privilege permissions
- Rotate access keys regularly

**Lambda:**
- Execution role with specific permissions
- No public access

**DynamoDB:**
- Private VPC access (optional)
- IAM-based access control

### Encryption

**In Transit:**
- TLS 1.2+ for all AWS API calls
- HTTPS for dashboard

**At Rest:**
- DynamoDB: AWS managed encryption
- Kinesis: Optional KMS encryption
- Lambda code: S3 server-side encryption

### Network Security

**VPC Configuration (Optional):**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           VPC                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Private Subnet           â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚  Lambda Function    â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  (No internet)      â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚                           â”‚  â”‚
â”‚  â”‚  VPC Endpoints:           â”‚  â”‚
â”‚  â”‚  â€¢ DynamoDB              â”‚  â”‚
â”‚  â”‚  â€¢ Kinesis               â”‚  â”‚
â”‚  â”‚  â€¢ CloudWatch Logs       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Monitoring

### CloudWatch Metrics

**Kinesis:**
- IncomingBytes
- IncomingRecords
- WriteProvisionedThroughputExceeded
- ReadProvisionedThroughputExceeded

**Lambda:**
- Invocations
- Errors
- Duration
- Throttles
- IteratorAge (for Kinesis)

**DynamoDB:**
- UserErrors
- SystemErrors
- ConsumedReadCapacityUnits
- ConsumedWriteCapacityUnits

### CloudWatch Logs

**Lambda Logs:**
```
/aws/lambda/kinesis-analytics-processor
```

**Log Retention:** 7 days (configurable to 1 day - 10 years)

### Alarms (Recommended)

1. **Lambda Errors > 10 in 5 minutes**
2. **Kinesis Iterator Age > 60 seconds**
3. **DynamoDB User Errors > 100 in 5 minutes**
4. **Lambda Throttles > 0**

## Cost Optimization

### Right-Sizing

**Kinesis:**
- Start with 1 shard
- Monitor IncomingBytes metric
- Add shards only when needed

**Lambda:**
- Use 256 MB memory (optimal for most workloads)
- Monitor Duration metric
- Increase only if timeout occurs

**DynamoDB:**
- Use On-Demand mode for variable traffic
- Switch to Provisioned mode for consistent high traffic
- Enable auto-scaling

### Cost Monitoring

**Set Budget Alerts:**
```bash
aws budgets create-budget \
  --account-id YOUR_ACCOUNT_ID \
  --budget file://budget.json
```

**Enable Cost Anomaly Detection**

---

## Performance Benchmarks

### Expected Throughput

| Component | Throughput | Latency |
|-----------|-----------|---------|
| Data Collector | 1 record/10s per collector | N/A |
| Kinesis | 1000 records/sec (per shard) | < 1s |
| Lambda | 100 records/batch | 100-500ms |
| DynamoDB | 40,000 read/write per sec (on-demand) | < 10ms |
| Dashboard | 1 query/5s | 100-300ms |

### Bottleneck Analysis

**Current bottleneck:** Data collection frequency (10s)

**To increase throughput:**
1. Reduce collection interval
2. Add more data collectors
3. Increase Kinesis shards

---

**For deployment instructions, see [DEPLOYMENT.md](DEPLOYMENT.md)**
